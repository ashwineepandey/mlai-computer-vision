{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import utils as ut\n",
    "# import log\n",
    "# import matplotlib.pyplot as plt\n",
    "# from keras.datasets import fashion_mnist\n",
    "# from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU, BatchNormalization, Input\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import utils as ut\n",
    "import os\n",
    "import log\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras.optimizers import gradient_descent_v2\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = log.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ut.timer\n",
    "def load_fashion_mnist_data():\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    X_train = np.repeat(X_train[..., np.newaxis], 3, -1)\n",
    "    X_test = np.repeat(X_test[..., np.newaxis], 3, -1)\n",
    "    \n",
    "    X_train = np.asarray([tf.image.resize(img, (32, 32)).numpy() for img in X_train])\n",
    "    X_test = np.asarray([tf.image.resize(img, (32, 32)).numpy() for img in X_test])\n",
    "    \n",
    "    X_train = preprocess_input(X_train)\n",
    "    X_test = preprocess_input(X_test)\n",
    "    \n",
    "    y_train = to_categorical(y_train, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "@ut.timer\n",
    "def load_pretrained_model(pretrained_model, weights, include_top=False):\n",
    "    # Load pre-trained VGG16 model without the top layer (which includes the classification layers)\n",
    "    base_model = pretrained_model(weights=weights, include_top=False, input_shape=(32, 32, 3))\n",
    "    return base_model\n",
    "\n",
    "@ut.timer\n",
    "def add_new_layers(base_model, dense_units, activation):\n",
    "    # Add new layers\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=dense_units, activation=activation)(x)\n",
    "    predictions = Dense(10, activation='softmax')(x) # For CIFAR10 data\n",
    "    # This is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "@ut.timer\n",
    "def freeze_layers(base_model):\n",
    "    # Freeze the layers of the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    _check_trainable_layers(base_model)\n",
    "    return base_model\n",
    "\n",
    "@ut.timer\n",
    "def unfreeze_layers(base_model):\n",
    "    # Unfreeze the layers of the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    _check_trainable_layers(base_model)\n",
    "    return base_model\n",
    "\n",
    "\n",
    "def _check_trainable_layers(model):\n",
    "    # get the configuration of each layer\n",
    "    layer_configs = model.get_config()['layers']\n",
    "\n",
    "    # print whether each layer is trainable or not\n",
    "    for i, layer_config in enumerate(layer_configs):\n",
    "        layer = model.layers[i]\n",
    "        logger.info(f\"Layer {i}: {layer.name}, trainable={layer.trainable}\")\n",
    "\n",
    "@ut.timer\n",
    "def compile_model(model, loss, metrics, learning_rate=0.0001, momentum=0.9):\n",
    "    opt = gradient_descent_v2.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    # We need to recompile the model for these modifications to take effect\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=metrics)\n",
    "\n",
    "@ut.timer\n",
    "def train_model(model: Model, \n",
    "                trainX: np.ndarray, \n",
    "                trainY: np.ndarray, \n",
    "                valX: np.ndarray, \n",
    "                valY: np.ndarray, \n",
    "                batch_size: int, \n",
    "                epochs: int, \n",
    "                model_path: str, \n",
    "                model_name: str, \n",
    "                datetime: str) -> History:\n",
    "    \"\"\"\n",
    "    Trains the CNN model on the training set and validates on the validation set.\n",
    "    \"\"\"\n",
    "    # define the callback to save the weights\n",
    "    checkpoint = ModelCheckpoint(f'{model_path}{model_name}_classifier_{datetime}.h5', \n",
    "                                 monitor='val_accuracy', \n",
    "                                 save_best_only=True, \n",
    "                                 save_weights_only=True, \n",
    "                                 verbose=1)\n",
    "\n",
    "    history = model.fit(trainX, trainY,\n",
    "                        validation_data=(valX, valY),\n",
    "                        callbacks=[checkpoint], \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs,\n",
    "                        verbose=1)    \n",
    "    return model, history\n",
    "\n",
    "@ut.timer\n",
    "def main():\n",
    "    # load config\n",
    "    conf = ut.load_config()\n",
    "    # load data\n",
    "    trainX, trainY, testX, testY = load_fashion_mnist_data()\n",
    "    # split training data into training and validation sets\n",
    "    trainX, trainY, valX, valY = ut.split_dataset(trainX, trainY)\n",
    "    # convert image data to float32 and normalize\n",
    "    trainX, _, valX = ut.convert_image_data(trainX, testX, valX)\n",
    "    # one-hot encode labels\n",
    "    trainY, _, valY = ut.encode_labels(trainY, testY, valY)\n",
    "    # get datetime\n",
    "    datetime = ut.get_current_dt()\n",
    "    # load pre-trained model\n",
    "    base_model = load_pretrained_model(pretrained_model=VGG16, weights='imagenet', include_top=False)\n",
    "    # freeze layers\n",
    "    freeze_layers(base_model)\n",
    "    # add new layers\n",
    "    model = add_new_layers(base_model, dense_units=512, activation='relu')\n",
    "    # compile model\n",
    "    compile_model(model, loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  learning_rate=conf.a3.classifier_params.learning_rate[0], \n",
    "                  momentum=conf.a3.classifier_params.momentum[0])\n",
    "    # train model\n",
    "    _, history = train_model(model, trainX, trainY, valX, valY, \n",
    "                        batch_size=conf.a3.classifier_params.batch_size, \n",
    "                        epochs=conf.a3.classifier_params.epochs,\n",
    "                        model_path=conf.a3.paths.model, \n",
    "                        model_name=\"vgg16\", \n",
    "                        datetime=datetime)\n",
    "    # unfreeze layers\n",
    "    unfreeze_layers(base_model)\n",
    "    # compile model\n",
    "    compile_model(model, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # train model\n",
    "    model, history = train_model(model, trainX, trainY, valX, valY, \n",
    "                        batch_size=conf.a3.classifier_params.batch_size, \n",
    "                        epochs=conf.a3.classifier_params.epochs,\n",
    "                        model_path=conf.a3.paths.model, \n",
    "                        model_name=\"vgg16\", \n",
    "                        datetime=datetime)\n",
    "    # Save the trained model\n",
    "    model.save(f\"{conf.a3.paths.model}fashion_mnist_classifier_{datetime}.h5\")\n",
    "    # save trained model and training history\n",
    "    ut.save_history(conf.a3.paths.train_history, history, \"fashionMNIST\", \"\", datetime)\n",
    "    fig = ut.plot_performance(history, dataset=\"validation\")\n",
    "    ut.save_plot(conf.a3.paths.train_plots, fig, \"validation\", datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-May-23 17:37:26 - INFO - Starting 'load_config'.\n",
      "06-May-23 17:37:26 - INFO - Finished 'load_config' in 0.0295 secs.\n",
      "06-May-23 17:37:26 - INFO - Starting 'load_fashion_mnist_data'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 17:37:27.414131: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-06 17:37:27.414240: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "06-May-23 17:38:27 - INFO - Finished 'load_fashion_mnist_data' in 61.1096 secs.\n",
      "06-May-23 17:38:27 - INFO - Starting 'split_dataset'.\n",
      "06-May-23 17:38:27 - INFO - Starting '_shuffle_data'.\n",
      "06-May-23 17:38:28 - INFO - Finished '_shuffle_data' in 0.3322 secs.\n",
      "06-May-23 17:38:28 - INFO - Finished 'split_dataset' in 0.3329 secs.\n",
      "06-May-23 17:38:28 - INFO - Starting 'convert_image_data'.\n",
      "06-May-23 17:38:28 - INFO - Finished 'convert_image_data' in 0.2840 secs.\n"
     ]
    }
   ],
   "source": [
    "conf = ut.load_config()\n",
    "trainX, trainY, testX, testY = load_fashion_mnist_data()\n",
    "trainX, trainY, valX, valY = ut.split_dataset(trainX, trainY)\n",
    "trainX, testX, valX = ut.convert_image_data(trainX, testX, valX)\n",
    "# trainY, testY, valY = ut.encode_labels(trainY, testY, valY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-May-23 17:38:28 - INFO - Starting 'load_pretrained_model'.\n",
      "06-May-23 17:38:28 - INFO - Finished 'load_pretrained_model' in 0.2517 secs.\n",
      "06-May-23 17:38:28 - INFO - Starting 'freeze_layers'.\n",
      "06-May-23 17:38:28 - INFO - Layer 0: input_1, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 1: block1_conv1, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 2: block1_conv2, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 3: block1_pool, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 4: block2_conv1, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 5: block2_conv2, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 6: block2_pool, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 7: block3_conv1, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 8: block3_conv2, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 9: block3_conv3, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 10: block3_pool, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 11: block4_conv1, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 12: block4_conv2, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 13: block4_conv3, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 14: block4_pool, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 15: block5_conv1, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 16: block5_conv2, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 17: block5_conv3, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Layer 18: block5_pool, trainable=False\n",
      "06-May-23 17:38:28 - INFO - Finished 'freeze_layers' in 0.0078 secs.\n",
      "06-May-23 17:38:28 - INFO - Starting 'add_new_layers'.\n",
      "06-May-23 17:38:28 - INFO - Finished 'add_new_layers' in 0.0187 secs.\n",
      "06-May-23 17:38:28 - INFO - Starting 'compile_model'.\n",
      "06-May-23 17:38:28 - INFO - Finished 'compile_model' in 0.0058 secs.\n"
     ]
    }
   ],
   "source": [
    "# get datetime\n",
    "datetime = ut.get_current_dt()\n",
    "# load pre-trained model\n",
    "base_model = load_pretrained_model(pretrained_model=VGG16, weights='imagenet', include_top=False)\n",
    "# freeze layers\n",
    "freeze_layers(base_model)\n",
    "# add new layers\n",
    "model = add_new_layers(base_model, dense_units=512, activation='relu')\n",
    "# compile model\n",
    "compile_model(model, loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                learning_rate=conf.a3.classifier_params.learning_rate[0], \n",
    "                momentum=conf.a3.classifier_params.momentum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-May-23 17:38:28 - INFO - Starting 'train_model'.\n",
      "2023-05-06 17:38:29.003872: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-05-06 17:38:29.004122: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 17:38:35.773356: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81/313 [======>.......................] - ETA: 12s - loss: 2.3745 - accuracy: 0.1528"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m _, history \u001b[39m=\u001b[39m train_model(model, trainX, trainY, valX, valY, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mconf\u001b[39m.\u001b[39;49ma3\u001b[39m.\u001b[39;49mclassifier_params\u001b[39m.\u001b[39;49mbatch_size, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mconf\u001b[39m.\u001b[39;49ma3\u001b[39m.\u001b[39;49mclassifier_params\u001b[39m.\u001b[39;49mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     model_path\u001b[39m=\u001b[39;49mconf\u001b[39m.\u001b[39;49ma3\u001b[39m.\u001b[39;49mpaths\u001b[39m.\u001b[39;49mmodel, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                     model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvgg16\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     datetime\u001b[39m=\u001b[39;49mdatetime)\n",
      "File \u001b[0;32m~/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/utils.py:26\u001b[0m, in \u001b[0;36mtimer.<locals>.wrapper_timer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStarting \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m---> 26\u001b[0m value \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     27\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     28\u001b[0m run_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32m/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb Cell 6\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, trainX, trainY, valX, valY, batch_size, epochs, model_path, model_name, datetime)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# define the callback to save the weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_path\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m_classifier_\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m                              monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m                              save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m                              save_weights_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m                              verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(trainX, trainY,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(valX, valY),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[checkpoint], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)    \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ashwineekumarpandey/Documents/Development/MLAI/GitHub/mlai-computer-vision/notebooks/AP-A3-002.ipynb#X33sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/engine/training.py:1163\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1161\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1163\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1165\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/callbacks.py:436\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 436\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/callbacks.py:278\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    276\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    277\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 278\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/callbacks.py:298\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    296\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 298\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    301\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/callbacks.py:338\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    336\u001b[0m hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(callback, \u001b[39m'\u001b[39m\u001b[39m_supports_tf_logs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 338\u001b[0m   hook(batch, logs)\n\u001b[1;32m    339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m   \u001b[39mif\u001b[39;00m numpy_logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Only convert once.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/callbacks.py:1044\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1044\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/callbacks.py:1108\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1107\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1109\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/utils/tf_utils.py:507\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    505\u001b[0m   \u001b[39mreturn\u001b[39;00m t  \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    863\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    864\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    866\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    868\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    863\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    864\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    866\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    868\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/keras/utils/tf_utils.py:503\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    502\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 503\u001b[0m     x \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    504\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    505\u001b[0m   \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1094\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \n\u001b[1;32m   1073\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1094\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlai_cvgan/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1060\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1059\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1061\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m     six\u001b[39m.\u001b[39mraise_from(core\u001b[39m.\u001b[39m_status_to_exception(e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmessage), \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "_, history = train_model(model, trainX, trainY, valX, valY, \n",
    "                    batch_size=conf.a3.classifier_params.batch_size, \n",
    "                    epochs=conf.a3.classifier_params.epochs,\n",
    "                    model_path=conf.a3.paths.model, \n",
    "                    model_name=\"vgg16\", \n",
    "                    datetime=datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = ut.load_config()\n",
    "# load data\n",
    "trainX, trainY, testX, testY = load_fashion_mnist_data()\n",
    "# split training data into training and validation sets\n",
    "trainX, trainY, valX, valY = ut.split_dataset(trainX, trainY)\n",
    "# convert image data to float32 and normalize\n",
    "trainX, trainY, valX = ut.convert_image_data(trainX, testX, valX)\n",
    "# one-hot encode labels\n",
    "trainY, testY, valY = ut.encode_labels(trainY, testY, valY)\n",
    "# get datetime\n",
    "datetime = ut.get_current_dt()\n",
    "# load pre-trained model\n",
    "base_model = load_pretrained_model(pretrained_model=VGG16, weights='imagenet', include_top=False)\n",
    "# freeze layers\n",
    "freeze_layers(base_model)\n",
    "# add new layers\n",
    "model = add_new_layers(base_model, dense_units=512, activation='relu')\n",
    "# compile model\n",
    "compile_model(model, loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                learning_rate=conf.a3.classifier_params.learning_rate[0], \n",
    "                momentum=conf.a3.classifier_params.momentum[0])\n",
    "# train model\n",
    "_, history = train_model(model, trainX, trainY, valX, valY, \n",
    "                    batch_size=conf.a3.classifier_params.batch_size, \n",
    "                    epochs=conf.a3.classifier_params.epochs,\n",
    "                    model_path=conf.a3.paths.model, \n",
    "                    model_name=\"vgg16\", \n",
    "                    datetime=datetime)\n",
    "# unfreeze layers\n",
    "unfreeze_layers(base_model)\n",
    "# compile model\n",
    "compile_model(model, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# train model\n",
    "model, history = train_model(model, trainX, trainY, valX, valY, \n",
    "                    batch_size=conf.a3.classifier_params.batch_size, \n",
    "                    epochs=conf.a3.classifier_params.epochs,\n",
    "                    model_path=conf.a3.paths.model, \n",
    "                    model_name=\"vgg16\", \n",
    "                    datetime=datetime)\n",
    "# Save the trained model\n",
    "model.save(f\"{conf.a3.paths.model}fashion_mnist_classifier_{datetime}.h5\")\n",
    "# save trained model and training history\n",
    "ut.save_history(conf.a3.paths.train_history, history, \"fashionMNIST\", \"\", datetime)\n",
    "fig = ut.plot_performance(history, dataset=\"validation\")\n",
    "ut.save_plot(conf.a3.paths.train_plots, fig, \"validation\", datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai_cvgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
