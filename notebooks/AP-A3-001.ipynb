{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import utils as ut\n",
    "import log\n",
    "from scipy.stats import entropy\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, LeakyReLU, BatchNormalization, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = log.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ut.timer\n",
    "def load_data():\n",
    "    # Load the Fashion-MNIST dataset\n",
    "    (X_train, _), (_, _) = fashion_mnist.load_data()\n",
    "    X_train = X_train / 127.5 - 1.0 # Normalize the images to [-1, 1]\n",
    "    return np.expand_dims(X_train, axis=3)\n",
    "\n",
    "\n",
    "# Generator\n",
    "@ut.timer\n",
    "def create_generator():\n",
    "    generator = Sequential([\n",
    "        Dense(128, input_dim=100),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        Dense(256),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        Dense(512),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        Dense(1024),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(28 * 28 * 1, activation='tanh'),\n",
    "        Reshape((28, 28, 1))\n",
    "    ])\n",
    "\n",
    "    return generator\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "@ut.timer\n",
    "def create_discriminator():\n",
    "    discriminator = Sequential([\n",
    "        Input(shape=(28, 28, 1)),\n",
    "        Flatten(),\n",
    "        Dense(512),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(256),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "\n",
    "# GAN\n",
    "@ut.timer\n",
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    return gan\n",
    "\n",
    "\n",
    "@ut.timer\n",
    "def compile_models(discriminator, generator):\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "    return gan\n",
    "\n",
    "\n",
    "@ut.timer\n",
    "def sample_images(generator, epoch, img_out_path, datetime):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    # Rescale images from [-1, 1] to [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(f\"{img_out_path}/{datetime}_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def _train_discriminator(discriminator, generator, X_train, conf):\n",
    "    # Train discriminator\n",
    "    idx = np.random.randint(0, X_train.shape[0], conf.a3.gan_params.batch_size)\n",
    "    real_imgs = X_train[idx]\n",
    "    noise = np.random.normal(0, 1, (conf.a3.gan_params.batch_size, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    \n",
    "    real_y = np.ones((conf.a3.gan_params.batch_size, 1))\n",
    "    fake_y = np.zeros((conf.a3.gan_params.batch_size, 1))\n",
    "    \n",
    "    d_loss_real = discriminator.train_on_batch(real_imgs, real_y)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake_y)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    return d_loss\n",
    "\n",
    "\n",
    "def _train_generator(gan, conf):\n",
    "    # Train generator\n",
    "    noise = np.random.normal(0, 1, (conf.a3.gan_params.batch_size, 100))\n",
    "    y = np.ones((conf.a3.gan_params.batch_size, 1))\n",
    "    g_loss = gan.train_on_batch(noise, y)\n",
    "    return g_loss\n",
    "\n",
    "\n",
    "def _preprocess_images(images):\n",
    "    # Resize images from (28, 28, 1) to (32, 32, 1)\n",
    "    resized_images = tf.image.resize(images, (32, 32), method=tf.image.ResizeMethod.BILINEAR)\n",
    "    # Convert grayscale images to RGB by duplicating the single channel three times\n",
    "    rgb_images = tf.repeat(resized_images, repeats=3, axis=-1)\n",
    "    return rgb_images\n",
    "\n",
    "# Train GAN\n",
    "@ut.timer\n",
    "def train_gan(X_train, generator, discriminator, gan, classifier, conf, datetime):\n",
    "    inception_scores = []\n",
    "    for epoch in range(conf.a3.gan_params.epochs):\n",
    "        # Train discriminator\n",
    "        d_loss = _train_discriminator(discriminator, generator, X_train, conf)\n",
    "        # Train generator\n",
    "        g_loss = _train_generator(gan, conf)\n",
    "        if epoch % conf.a3.gan_params.sample_interval == 0:\n",
    "            logger.info(f\"Epoch {epoch}, D-Loss: {d_loss[0]}, G-Loss: {g_loss}\")\n",
    "            sample_images(generator, epoch, conf.a3.paths.training_inspection_plots, datetime)\n",
    "            gen_imgs = generate_images(generator, \n",
    "                                    conf.a3.gan_params.noise_dim, \n",
    "                                    conf.a3.gan_params.num_samples)\n",
    "            gen_imgs_processed = _preprocess_images(gen_imgs)\n",
    "            pred, _ = make_prediction(classifier, gen_imgs_processed)\n",
    "            score = inception_score(pred, \n",
    "                                       conf.a3.gan_params.num_classes, \n",
    "                                       conf.a3.gan_params.epsilon)\n",
    "            inception_scores.append((epoch, score))\n",
    "            logger.info(f\"Inception Score: {score}\")\n",
    "    pred, labels = make_prediction(classifier, gen_imgs_processed)\n",
    "    fig = plot_class_distribution(labels, \n",
    "                                  conf.a3.fashion_mnist_class_labels)\n",
    "    save_plot(fig, conf.a3.paths.training_inspection_plots, \"classification-distribution\", datetime)\n",
    "    fig = plot_inception_score(inception_scores)\n",
    "    save_plot(fig, conf.a3.paths.training_inspection_plots, \"inception-score\", datetime)   \n",
    "    return generator, discriminator, gan\n",
    "\n",
    "@ut.timer\n",
    "def save_models(generator, discriminator, gan, model_out_path, datetime):\n",
    "    generator.save(f\"{model_out_path}{datetime}_generator.h5\")\n",
    "    discriminator.save(f\"{model_out_path}{datetime}_discriminator.h5\")\n",
    "    gan.save(f\"{model_out_path}{datetime}_gan.h5\")\n",
    "    logger.info(\"Models saved successfully\")\n",
    "\n",
    "\n",
    "@ut.timer\n",
    "def load_pretrained_classifier(model_path):\n",
    "    model = load_model(model_path)\n",
    "    return model\n",
    "\n",
    "@ut.timer\n",
    "def make_prediction(classifier, images: np.ndarray):\n",
    "    # Predict the labels\n",
    "    pred = classifier.predict(images)\n",
    "    # Get the class with the highest probability for each image\n",
    "    class_labels = np.argmax(pred, axis=1)\n",
    "    return pred, class_labels\n",
    "\n",
    "\n",
    "@ut.timer\n",
    "def inception_score(pred, num_classes: int, eps: float = 1e-16) -> Tuple[float, float]:\n",
    "    # Compute the KL divergence for each image\n",
    "    kl = pred * (np.log(pred + eps) - np.log(1.0 / num_classes))\n",
    "    # Compute the average KL divergence\n",
    "    avg_kl = np.mean(np.sum(kl, axis=1))\n",
    "    # Compute the inception score\n",
    "    score = np.exp(avg_kl)\n",
    "    return score\n",
    "\n",
    "\n",
    "@ut.timer\n",
    "def generate_images(generator, noise_dim, num_samples):\n",
    "    # Generate a batch of images\n",
    "    noise = np.random.normal(0, 1, (num_samples, noise_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images from [-1, 1] to [0, 1]\n",
    "    return gen_imgs\n",
    "\n",
    "\n",
    "def plot_class_distribution(labels, class_labels):\n",
    "    # Count the number of images per class\n",
    "    counts = np.zeros(len(class_labels))\n",
    "    for label in labels:\n",
    "        counts[label] += 1\n",
    "    # # Prepare the data for the barplot\n",
    "    # data = {'Class': np.arange(num_classes), 'Number of Images': counts}\n",
    "    # Create a dataframe with the labels and counts\n",
    "    data = pd.DataFrame({'Label': [class_labels[label] for label in list(range(10))], 'Count': counts})\n",
    "    # Plot the barplot using plotly.express\n",
    "    fig = px.bar(data, x='Label', y='Count', title='Generated Images per Class', text='Count')\n",
    "    fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n",
    "    return fig\n",
    "\n",
    "@ut.timer\n",
    "def save_plot(fig, plot_filepath, title, datetime):\n",
    "    prefix = f\"{title}-{datetime}.png\"\n",
    "    filepath = os.path.join(plot_filepath, prefix)\n",
    "    # save figure to file\n",
    "    fig.write_image(filepath)\n",
    "    logger.info(f\"Plot saved: {filepath}\")\n",
    "\n",
    "@ut.timer\n",
    "def plot_inception_score(inception_scores):\n",
    "    iterations = [score[0] for score in inception_scores]\n",
    "    scores = [score[1] for score in inception_scores]\n",
    "    data = pd.DataFrame({'Iterations': iterations, 'Inception Score': scores})\n",
    "    fig = px.line(data, x='Iterations', y='Inception Score', markers=True, title='Inception Score vs Training Iterations')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load config\n",
    "    conf = ut.load_config()\n",
    "    classifier = load_pretrained_classifier(model_path=conf.a3.paths.classifier_model)\n",
    "    X_train = load_data()\n",
    "    generator = create_generator()\n",
    "    discriminator = create_discriminator()\n",
    "    gan = compile_models(discriminator, generator)\n",
    "    dt = ut.get_current_dt()\n",
    "    # Set parameters and train the GAN\n",
    "    generator, discriminator, gan = train_gan(X_train, generator, discriminator, gan, classifier, conf, dt)\n",
    "    # Save models\n",
    "    save_models(generator, discriminator, gan, conf.a3.paths.model, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-May-23 20:58:36 - INFO - Starting 'load_config'.\n",
      "06-May-23 20:58:36 - INFO - Finished 'load_config' in 0.0563 secs.\n",
      "06-May-23 20:58:36 - INFO - Starting 'load_pretrained_classifier'.\n",
      "06-May-23 20:58:37 - INFO - Finished 'load_pretrained_classifier' in 0.1614 secs.\n",
      "06-May-23 20:58:37 - INFO - Starting 'load_data'.\n",
      "06-May-23 20:58:37 - INFO - Finished 'load_data' in 0.4093 secs.\n",
      "06-May-23 20:58:37 - INFO - Starting 'create_generator'.\n",
      "06-May-23 20:58:37 - INFO - Finished 'create_generator' in 0.0428 secs.\n",
      "06-May-23 20:58:37 - INFO - Starting 'create_discriminator'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-May-23 20:58:37 - INFO - Finished 'create_discriminator' in 0.0148 secs.\n",
      "06-May-23 20:58:37 - INFO - Starting 'compile_models'.\n",
      "06-May-23 20:58:37 - INFO - Starting 'create_gan'.\n",
      "06-May-23 20:58:37 - INFO - Finished 'create_gan' in 0.0214 secs.\n",
      "06-May-23 20:58:37 - INFO - Finished 'compile_models' in 0.0283 secs.\n",
      "06-May-23 20:58:37 - INFO - Starting 'train_gan'.\n",
      "2023-05-06 20:58:37.591615: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-06 20:58:37.722599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-05-06 20:58:37.999859: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "06-May-23 20:58:38 - INFO - Epoch 0, D-Loss: 0.7620559930801392, G-Loss: 0.6296145915985107\n",
      "06-May-23 20:58:38 - INFO - Starting 'sample_images'.\n",
      "2023-05-06 20:58:38.209321: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "06-May-23 20:58:38 - INFO - Finished 'sample_images' in 0.2040 secs.\n",
      "06-May-23 20:58:38 - INFO - Starting 'generate_images'.\n",
      "06-May-23 20:58:38 - INFO - Finished 'generate_images' in 0.0941 secs.\n",
      "06-May-23 20:58:38 - INFO - Starting 'make_prediction'.\n",
      "2023-05-06 20:58:38.698385: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "06-May-23 20:58:38 - INFO - Finished 'make_prediction' in 0.4580 secs.\n",
      "06-May-23 20:58:38 - INFO - Starting 'inception_score'.\n",
      "06-May-23 20:58:38 - INFO - Finished 'inception_score' in 0.0003 secs.\n",
      "06-May-23 20:58:38 - INFO - Inception Score: 2.8881638050079346\n",
      "06-May-23 20:58:39 - INFO - Epoch 2, D-Loss: 0.5349330343306065, G-Loss: 0.22472558915615082\n",
      "06-May-23 20:58:39 - INFO - Starting 'sample_images'.\n",
      "06-May-23 20:58:39 - INFO - Finished 'sample_images' in 0.2848 secs.\n",
      "06-May-23 20:58:39 - INFO - Starting 'generate_images'.\n",
      "06-May-23 20:58:39 - INFO - Finished 'generate_images' in 0.0443 secs.\n",
      "06-May-23 20:58:39 - INFO - Starting 'make_prediction'.\n",
      "06-May-23 20:58:39 - INFO - Finished 'make_prediction' in 0.2048 secs.\n",
      "06-May-23 20:58:39 - INFO - Starting 'inception_score'.\n",
      "06-May-23 20:58:39 - INFO - Finished 'inception_score' in 0.0002 secs.\n",
      "06-May-23 20:58:39 - INFO - Inception Score: 3.3639132976531982\n",
      "06-May-23 20:58:39 - INFO - Starting 'make_prediction'.\n",
      "06-May-23 20:58:39 - INFO - Finished 'make_prediction' in 0.1706 secs.\n",
      "06-May-23 20:58:40 - INFO - Starting 'save_plot'.\n",
      "06-May-23 20:58:40 - INFO - Plot saved: ../data/07_model_output/A3/training_inspection/classification-distribution-06052023_205837.png\n",
      "06-May-23 20:58:40 - INFO - Finished 'save_plot' in 0.6645 secs.\n",
      "06-May-23 20:58:40 - INFO - Starting 'plot_inception_score'.\n",
      "06-May-23 20:58:40 - INFO - Finished 'plot_inception_score' in 0.0278 secs.\n",
      "06-May-23 20:58:40 - INFO - Starting 'save_plot'.\n",
      "06-May-23 20:58:40 - INFO - Plot saved: ../data/07_model_output/A3/training_inspection/inception-score-06052023_205837.png\n",
      "06-May-23 20:58:40 - INFO - Finished 'save_plot' in 0.0240 secs.\n",
      "06-May-23 20:58:40 - INFO - Finished 'train_gan' in 3.1986 secs.\n",
      "06-May-23 20:58:40 - INFO - Starting 'save_models'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06-May-23 20:58:40 - INFO - Models saved successfully\n",
      "06-May-23 20:58:40 - INFO - Finished 'save_models' in 0.1122 secs.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlai_cvgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
